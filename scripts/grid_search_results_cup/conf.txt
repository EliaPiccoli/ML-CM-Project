model = Model()
model._add_layer(Layer(8, "leaky_relu", _input=(10,)))
model._add_layer(Layer(8, "leaky_relu"))
model._add_layer(Layer(8, "leaky_relu"))
model._add_layer(Layer(2, "linear"))
model._compile(eta=0.000005, loss_function="mse", alpha=0.98, _lambda=1e-1)
epoch = 50
classification=False
stats = model._train(train, train_labels, validation, validation_labels, decay=1e-6,batch_size=len(train), epoch=epoch, classification=classification, verbose=True)


Configuration 0, score : 16957.11546976781, test_mee : 16.94111546976781, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 0.0001, 'alpha': 0.98, '_lambda': 1e-05}
Configuration 1, score : 16957.307318331514, test_mee : 16.941307318331514, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 0.0001, 'alpha': 0.8, '_lambda': 1e-05}
Configuration 2, score : 16958.028426206783, test_mee : 16.942028426206782, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 0.0001, 'alpha': 0.98, '_lambda': 0.0001}
Configuration 3, score : 16958.311830039846, test_mee : 16.942311830039845, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 0.0001, 'alpha': 0.8, '_lambda': 0.0001}
Configuration 4, score : 16966.517839418968, test_mee : 16.950517839418968, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 0.0001, 'alpha': 0.98, '_lambda': 0.001}
Configuration 5, score : 16966.84436189511, test_mee : 16.95084436189511, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 0.0001, 'alpha': 0.8, '_lambda': 0.001}
Configuration 6, score : 17029.04001951917, test_mee : 16.99704001951917, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 8e-05, 'alpha': 0.98, '_lambda': 1e-05}
Configuration 7, score : 17029.33656665952, test_mee : 16.99733656665952, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 8e-05, 'alpha': 0.8, '_lambda': 1e-05}

Configuration 0, score : 26279.1238106067, test_mee : 26.2191238106067, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.8, '_lambda': 0.0001}
Configuration 1, score : 26422.542354651734, test_mee : 26.402542354651732, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.98, '_lambda': 1e-05}
Configuration 2, score : 26639.75040336922, test_mee : 26.629750403369222, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.8, '_lambda': 1e-05}
Configuration 3, score : 26660.24970998519, test_mee : 26.65024970998519, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.8, '_lambda': 0.001}
Configuration 4, score : 27149.3983905445, test_mee : 27.091398390544498, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.98, '_lambda': 0.001}
Configuration 5, score : 27687.058534441676, test_mee : 27.617058534441675, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.98, '_lambda': 0.0001}
Configuration 6, score : 37143.473719897236, test_mee : 37.10347371989724, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 0.0001, 'alpha': 0.98, '_lambda': 0.001}
Configuration 7, score : 37542.09464197116, test_mee : 37.48409464197116, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 8e-05, 'alpha': 0.98, '_lambda': 0.0001}

Configuration 0, score : 30321.159597399434, test_mee : 30.271159597399432, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.8, '_lambda': 1e-05}
Configuration 1, score : 30655.22796161518, test_mee : 30.605227961615178, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.98, '_lambda': 0.001}
Configuration 2, score : 30745.936401934305, test_mee : 30.695936401934304, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.8, '_lambda': 0.0001}
Configuration 3, score : 30754.8908337976, test_mee : 30.7048908337976, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.8, '_lambda': 0.001}
Configuration 4, score : 30812.51974868516, test_mee : 30.76251974868516, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.98, '_lambda': 0.0001}
Configuration 5, score : 31179.013423306955, test_mee : 31.129013423306954, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 5e-05, 'alpha': 0.98, '_lambda': 1e-05}
Configuration 6, score : 71404.32148815233, test_mee : 71.34432148815233, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 8e-05, 'alpha': 0.98, '_lambda': 1e-05}
Configuration 7, score : 71605.37992052273, test_mee : 71.55537992052273, params:{'epoch': 200, 'batch_size': 916, 'lr_decay': 1e-05, 'eta': 8e-05, 'alpha': 0.8, '_lambda': 0.001}
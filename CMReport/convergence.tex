\documentclass[12pt]{article}
\usepackage{graphicx} % for inserting images
\usepackage[utf8]{inputenc} % for good practice
\usepackage{amsmath} % for equations
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{setspace}
\usepackage{siunitx}
\usepackage{csquotes}
\usepackage[
backend=biber,
sorting=ynt
]{biblatex}
\sisetup{output-exponent-marker=\ensuremath{\mathrm{e}}}
\addbibresource{biblio.bib}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\Lagr}{\mathcal{L}}
\DeclareUnicodeCharacter{2212}{-}

\title{Support Vector Regression\\using\\Deflected Subgradient Methods}
\author{Elia Piccoli\\Nicola Gugole}
\begin{document}
	\begin{titlepage}
		\maketitle
		\pagenumbering{gobble}
	   \begin{center}
		\vspace{0.5cm}
	        A project presented for the\\\textit{Computational Mathematics for Learning and Data Analysis}\\course
	       \vfill	     
	       \includegraphics[width=0.2\textwidth]{unipi.png}\\
	       University of Pisa\\
	       Artificial Intelligence\\
	       A.Y. 2020/2021\\
	            
	   \end{center}
	\end{titlepage}
	
	\newpage
	\tableofcontents
	\vspace{4cm}
	\begin{abstract}
		 Project aim is developing the implementation of a model which follows an SVR-type approach including various different kernels. The implementation uses as optimization algorithm a dual approach with appropriate choices of the constraints to be dualized, where the Lagrangian Dual is solved by an algorithm of the class of deflected subgradient methods.
	\end{abstract}
	\pagenumbering{arabic} %per rimettere i numeri di pagina
	\pagebreak
	
	\section{Introduction}
	SVR objective is predicting a uni-dimensional real-valued output $y$ through the use of an \textit{objective function} built by optimization using an $\varepsilon$-insensitive loss function. Another fundamental aspect about SVR is keeping the function \textit{as flat as possible} through the tuning of a $C$ parameter in order to avoid overfitting and generating a correct trade-off between accuracy and generalization.\\
	The resulting function can be generically described as:
	\begin{equation}\label{eq:1}
		f(x) = w  x + b
	\end{equation}
	Keeping the above function \textit{as flat as possible} is equivalent to an optimization problem formulated as having minimum $\norm{w}$, or, for a more convenient mathematical derivation, minimum $\norm{w}^2$, not changing the semantics of the problem.\\
	This brings us to a convex minimization problem, which will be called \textit{primal problem}:
    \begin{equation}\label{eq:2}
		\min_{w,\xi_i,\xi_i^*} \frac{1}{2}\norm{w}^2+C\sum_{i}(\xi_{i} + \xi_{i}^*)
	\end{equation}
	Where $\xi$ and $\xi^*$ are called \textit{slack variables}, used in conjunction with $C$ to create a \textit{regularization factor} and consequently a \textit{penalty measure} to elements which are not part of the $\varepsilon$-tube. Slack variables allow the definition of constraints applicable to \eqref{eq:2}:
	\begin{subequations}
    	\begin{align}
    		&y_i - w^T\phi(x_i) - b \leq \varepsilon + \xi_i,  \label{eq:3a}\\ 
    		&b + w^T\phi(x_i) - y_i \leq \varepsilon + \xi_i, \label{eq:3b}\\
    		&\xi_i,\xi_i^*  \geq 0 \label{eq:3c}
    	\end{align}
	\end{subequations}
	\begin{center}
		\footnotesize{$x_i$ input, $y_i$ output}
	\end{center}
	\pagebreak
	
	\section{Dual Representation}
	As expressed in the abstract, the implementation will follow a dual approach, which in SVR models is preferred due to the applicability and efficiency of the use of \textit{kernels}. \textit{Dual problem} formulation can be achieved defining the \textit{Lagrangian} function:
	\begin{equation}\label{eq:4}
    	\begin{aligned}
    		\Lagr(\alpha,\alpha^*,\mu,\mu^*) =  \ &\frac{1}{2}\norm{w}^2\\
    		&+C\sum_{i=1}^{m}(\xi_{i} + \xi_{i}^*) \\
    		&+ \sum_{i=1}^{m}(\alpha_i(y_i - w^T\phi(x_i) - b - \varepsilon - \xi_i))\\
    		&+ \sum_{i=1}^{m}(\alpha_i^*(w^T\phi(x_i) + b - y_i - \varepsilon - \xi_i^*)) \\
    		&- \sum_{i=1}^{m}(\mu_i\xi_i + \mu_i^*\xi_i^*)
    	\end{aligned}
	\end{equation}
	
	From which the following optimization problem can be obtained (full derivation shown in \ref{appendixA}):
	\begin{equation}\label{eq:5}
    	\begin{aligned}
    		\max_{\alpha_i,\alpha_i^*} &- \frac{1}{2}\sum_i\sum_j(\alpha_i - \alpha_i^*)(\alpha_j - \alpha_j^*)K(x_i,x_j) \\
    		&- \varepsilon\sum_i(\alpha_i + \alpha_i^*)\\
    		&+ \sum_i y_i(\alpha_i - \alpha_i^*)
    	\end{aligned}
	\end{equation}
	With constraints:
	\begin{subequations}
		\begin{align}
    		&\forall i \: \alpha_i,\alpha_i^* \geq 0 \qquad\qquad &&(KKT\;condition) \label{eq:6a}\\
    		&\forall i \: \alpha_i,\alpha_i^* \in [0,C]  \qquad\qquad &&(from \: derivation)\label{eq:6b}\\
    		&\forall i \: \sum (\alpha_i - \alpha_i^*) = 0 \qquad\qquad &&(from \: derivation)\label{eq:6c}\\
    		&\forall i \: \alpha_i \alpha_i^* = 0 \qquad\qquad &&(from \: model \: construction)\label{eq:6d}
		\end{align}
	\end{subequations}
	\newline
	At this point a reformulation of \eqref{eq:5} is necessary to follow the task objective, which is solving the \textit{Lagrangian Dual} maximization with a subgradient method, therefore requiring a \textit{non-differentiable function}. Such function is achievable with a simple variable substitution:
	\begin{equation*}
	    \begin{aligned}
    	    &\;\beta_i \longleftarrow (\alpha_i - \alpha_i^*) \\
    	    &\abs{\beta_i} \longleftarrow (\alpha_i + \alpha_i^*)
	    \end{aligned}
	\end{equation*}
	Bringing the definitive dual problem definition:
	\begin{equation}\label{eq:7}
	    \begin{aligned}
    	    \max_{\beta_i} &- \frac{1}{2}\sum_i \sum_j \beta_i \beta_j K(x_i,x_j) \\
    		&- \varepsilon\sum_i\abs{\beta_i}\\
    		&+ \sum_i y_i\beta_i\\
    		&With\;the\;constraints\qquad
            \begin{cases}
                \sum_i \beta_i = 0 \\
                \;\beta_i\in[-C,\;C] 
            \end{cases}
        \end{aligned}
	\end{equation}
	It is important to notice how the above formulation defines a convex non-differentiable problem which still maintains the \textit{strong duality} propriety, assuring that the optimal solution of the dual problem (\textit{computationally less intensive}) coincides with the one of the primal problem.
	\pagebreak
	\section{Deflected Subgradient Algorithm}
	In order to solve the problem defined in \eqref{eq:7} we need to use an algorithm among the family of \textit{subgradients methods}.
    The approach that we are going to analyze is a \textit{Constrained Deflected Subgradient Method} using \textit{Target Value Stepsize} with a \textit{Non-Vanishing Threshold}.\\
    Let's briefly analyze all the elements that characterize the approach:
    \begin{itemize}
        \item \textit{Constrained}: as we can see in \eqref{eq:7} the dual problem variable $\beta$ is subject to linear and box constraints that the algorithm must respect at each step.
        
        \item \textit{Deflected}: at each step of the algorithm the direction will be a convex combination wrt to the previous direction and the current subgradient.
        \begin{equation}\label{eq:8}
            d_k = \alpha g_k + (1 - \alpha) d_{k-1} \qquad \alpha \in [0,\;1]
        \end{equation}
        
        \item \textit{Target Value Stepsize} with a \textit{Non-Vanishing Threshold}: since $f^*$ is unknown, we will use a \textit{target level} approach where $f^*$ is approximated by an estimate that is updated as the algorithm proceeds. The estimate is defined wrt two values: $f_{ref}^k$ which is the \emph{reference value}, and $\delta_k$ which is the \emph{threshold}. This two values will be used to approximate $f^*$ in the formulation of the stepsize. In particular the stepsize has to follow a constraint between the $\alpha$ and $\psi$ parameter (\textit{stepsize restriction}) to assure convergence.
        \begin{equation}\label{eq:9}
            0 \leq \nu_k = \psi_k \frac{f_k - f_{ref}^k + \delta_k}{\norm{d_k}^2} \qquad 0 \leq \psi_k \leq \alpha_k \leq 1 
        \end{equation}
        As far as concerns the \textit{non-vanishing threshold}, it will assure that at each step of the algorithm $\delta$ will always be grater than zero.
        \begin{equation}\label{eq:10}
            \forall_k \quad \delta_k > 0
        \end{equation}
    \end{itemize}
    \pagebreak
    Here is described a general algorithm for solving \eqref{eq:7}, which can be easily transformed into a \textit{minimization problem}.\\
    \newline
    \begin{algorithm}[H]
		\small
		\DontPrintSemicolon
		\label{algo:1}
		\setstretch{1.1}
		\Begin{
		$x_{ref} \longleftarrow x$\\
		$f_{ref} \longleftarrow \infty$\\
		$\delta \longleftarrow 0$\\
		$d_{prev} \longleftarrow 0$\\
		\While{true}{
			$v \longleftarrow \frac{1}{2}x'Kx + \varepsilon|x| - yx$\\
			$g \longleftarrow Kx + \varepsilon sgn(x) - y$\\
			\texttt{\textbf{Check if in $stopped/optimal$ condition}}\\
			\texttt{// reset $\delta$ if $v$ is \textit{good} or decrease it otherwise}\\
			\eIf{$v \leq f_{ref} - \delta$}{
				$\delta \longleftarrow \delta_{reset} \cdot \max{v,1}$\\
				}{
				$\delta \longleftarrow \max(\delta \rho , eps \cdot\max(\abs{ \min(v,f_{ref}) } , 1) )$\\
				}
			\texttt{// update $f_{ref}$ and $x_{ref}$ if needed}\\
			\If{$v < f_{ref}$}{
				$f_{ref} \longleftarrow v$\\
				$x_{ref} \longleftarrow x$\\
				}
			$d \longleftarrow \alpha g + (1 - \alpha)d_{prev}$\\
			$d \longleftarrow Project(d)$ \hfill \texttt{// project $d$  \hyperref[deflectproj]{(here)}}\\
			$d_{prev} \longleftarrow d$\\
			$\lambda \longleftarrow v-f_{ref}+\delta$\\
			$\nu \longleftarrow \frac{\psi \cdot \lambda}{\norm{d}^2}$ \hfill \texttt{// stepsize-restricted $\rightarrow \psi \leq \alpha$}\\
			$x \longleftarrow x - \nu\cdot d$\\
			$x \longleftarrow Project(x)$ \hfill \texttt{// project $x$ \hyperref[kpproj]{(here)}}\\
			}
		}
		 \caption{Deflected Subgradient Algorithm \\variable $x$ stands for $\beta$, $\delta_{reset} \approx 0\;( > 0 )$, $\rho \in [0,\;1]$}
	\end{algorithm}
	\pagebreak
	The projections required in \hyperref[algo:1]{Algorithm 1} are the ones presented in \hyperref[projections]{Section 4}. The two projections are \textit{easy} to perform, allowing the convergence of the \textit{Deflected Subgradient Algorithm} as stated in \parencite[see][Theorem 3.6]{deflectconv}.
	\begin{displayquote}
    	\textit{Theorem 3.6. Under conditions (2.13) and (3.5), the algorithm employing the level stepsize (3.19) with threshold condition (3.23) attains either:
    	\begin{itemize}
    	    \item[] $f_{ref}^{\infty} = -\infty = f^*$
    	    \item[] $f_{ref}^{\infty} \leq f^* + \xi \sigma^* + \delta^*,\;where\;0 \leq \xi = \max \{ 1 − \delta^* \Gamma / 2\sigma^*, 0 \} < 1$
    	\end{itemize}}
	\end{displayquote}
	Which in the case of a convex function, as \eqref{eq:7}, leads to the second possibility.
	The quoted \textit{level stepsize} is exactly \eqref{eq:9} and the \textit{threshold condition} is the \textit{non-vanishing threshold} \eqref{eq:10}.\\
	The theorem has two conditions to ensure the convergence (note that in our notation $v_{k+1} = d_{prev}$):
	\begin{itemize}
	    \item \parencite[Cond 2.13]{deflectconv} 
	    \begin{displayquote}
    	    \textit{
    	    $\tilde{d_k} = Deflected(d_k)$\\
    	    $\hat{d_k} = Projected(d_k)$\\
    	    Condition (2.12) holds if \qquad $d_k = \tilde{d_k} \implies v_{k+1} = \tilde{d_k}$}
        \end{displayquote}
        The above condition aims at assuring the satisfaction of (2.12):
        \begin{displayquote}
            $\langle d_k, x - x_k \rangle \leq \langle v_{k+1}, x - x_k \rangle$
        \end{displayquote}
        which in our case is correct since both $d_k = \hat{d_k}$ and $v_{k+1} = \hat{d_k}$.  
        [see \hyperref[algo:1]{\textit{Deflected Subgradient Algorithm}}]
	    \item \parencite[Cond 3.5]{deflectconv} 
	    \begin{displayquote}
            $\lambda_k \geq 0 \implies \alpha_k \geq \psi_k \geq \psi^* > 0 \\
            \lambda_k < 0 \implies \alpha_k = 0 (\implies \psi_k = 0)$
        \end{displayquote}
        Such a condition is satisfied since at each iteration $\lambda$ is always greater or equal to zero because of the algorithm structure and $\alpha_k$ is assured to maintain the correct ordering wrt $\psi_k$ since for the current version they are constant. [see \hyperref[algo:1]{\textit{Deflected Subgradient Algorithm}}].
	\end{itemize}
	In conclusion, the convergence of the algorithm is assured by the satisfaction of the requirements. Expected convergence rate is at best the convergence rate of a SM using \textit{Polyak stepsize}. This is derived from the fact that the proposed algorithm is a constrained approximation of Polyak using \textit{Target Level}, suggesting a best convergence of $\mathcal{O}(\frac{1}{\epsilon^2})$\\\parencite[as stated for \textit{Polyak stepsize: efficiency} in][Slide 41, "\textit{Good (bad) news: $\mathcal{O}(\frac{1}{\epsilon^2})$ optimal for nondifferentiable f}"]{slidesubgr}.

	\section{Projection Algorithms} \label{projections}
	In this section the focus will be on how the two projection problems are solved. \\
	\label{deflectproj}
	The first projection which will be analyzed is the \textit{direction projection} ensuring \textit{box constraints}. This projection is pretty \textit{easy} to achieve and can be performed \textit{linearly} by zeroing the direction components which are leading out of the feasible area. The process is linear since it implies passing through all the direction dimensions only once.\\
    \newline
    \begin{algorithm}[H]\label{algo:2}
	\DontPrintSemicolon
	\small
	\SetAlgoNoEnd
	\Begin{
		\texttt{$\forall_i \; x_i \in [-C,C]$}\\
		\For{$i\gets0$ \KwTo $size(d)$}{
				\If{$(-C -x_i < \epsilon $ and $ d_i < 0)$ or $(C - x_i < \epsilon$ and $d_i >0)$}{
				$d_i \longleftarrow 0$\\
				}
				}
	}
	 \caption{Project Direction \\($d$ is direction, $x$ is current point,  $\epsilon \approx 0$)}
	\end{algorithm}
	\vspace{0.5cm}
    \label{kpproj}$\emph{Convex Separable Knapsack Problem Algorithm}$. The constraints of the projection put it in the category of \textit{Knapsack Problems}, which for convex and separable problems (as is \eqref{eq:11}) a complexity of $\mathcal{O}(n\cdot log(n))$ can be promptly achieved, as stated in \parencite{cqknsp} exploiting the \textbf{Breakpoint Searching Algorithm} and its variants. In particular the following paragraphs discuss the solution of such a problem using the easiest algorithm discussed in \parencite{Kiwiel2008}. Starting from the projection formulation.
    
    \begin{equation}\label{eq:11}
	    \begin{aligned}
	    \min_{\beta_{proj}} \quad &\frac{1}{2}\norm{\beta - \beta_{proj}}^2\\ 
		&With\;the\;constraints\qquad
        \begin{cases}
            \sum_i \beta_{proj}^i = 0 \\
            \;\beta_{proj}^i\in[-C,\;C] 
        \end{cases}
        \end{aligned}
	\end{equation}
    
    Which by Lagrangian Relaxation leads to:
    
    \begin{equation}\label{eq:12}
	    \begin{aligned}
	    \Lagr = \min_{\beta_{proj}} \quad &\frac{1}{2}\norm{\beta - \beta_{proj}}^2 - \mu\sum\beta_{proj}^i\\ 
		&With\;the\;constraints\qquad
        \begin{cases}
            \;\beta_{proj}^i\in[-C,\;C] 
        \end{cases}
        \end{aligned}
	\end{equation}
	
	This allows a useful elaboration of $\mu$ and $\beta_{proj}^i$ by analyzing the derivative.
    \begin{equation}\label{eq:13}
        \begin{aligned}
            \frac{\partial{\Lagr}}{\partial{\beta_{proj}^i}} = -(\beta_i - \beta_{proj}^i) + \mu = 0 \\
    	    \implies \qquad \mu = \beta_i - \beta_{proj}^i\\
    	    \beta_{proj}^i = \beta_i - \mu\\
        \end{aligned}
	\end{equation}
	
	In order to find the optimal value for $\mu$ we now define some elements that will be computed each iteration of \hyperref[algo:1]{Algorithm 1}. These are needed in order to initialize all the elements required for the \textit{Breakpoint Search Algorithm} (\hyperref[algo:3]{Algorithm 3}). We can consider each component independently given the \textit{separable} structure of the problem.
	\begin{itemize}
	\item \textit{Upper} and \textit{lower} bound of $\mu$: for each component we will compute the maximum and minimum value of $\mu_i$ assigning to $\beta_{proj}^i$ the two extreme values \textit{-C/C} in \eqref{eq:13}.
    	\begin{equation}\label{eq:14}
    	    \begin{aligned}
    	        &\forall_i \quad \mu_i^u = \beta_i - C\\
    	        &\forall_i \quad \mu_i^l = \beta_i + C\\
    	    \end{aligned}
    	\end{equation}
	\item Definition of $\beta_{proj}^i$ wrt $\mu$: a piecewise linear and non-increasing function based on \eqref{eq:13} and fundamental for checking for early algorithm termination. Also once the algorithm terminates we can compute the correct value for each $\beta_{proj}^i$ given the value of $\mu^*$ .
	    \begin{equation}\label{eq:15}
            \begin{aligned}
                \beta_{proj}^i(\mu) = 
                \begin{cases}
                    C \qquad &if\;\mu < \mu_i^u\\
                    \beta_i - \mu &if\; \mu_i^u \leq \mu \leq \mu_i^l\\
                    -C &if\;\mu > \mu_i^l\\
                \end{cases}
            \end{aligned}
        \end{equation}
	\item \textit{h}: we define \textit{h} to be the function representing the linear constraint over the variables. This function is also a piecewise linear non-increasing function given the nature of its summation components. It will be evaluated in the algorithm to check if $\mu^*$ was found; otherwise it will work as oracle to guide the restriction of the set of possible values of $\mu$.
	\begin{equation}\label{eq:16}
	    h(\mu) = \sum_i \beta_{proj}^i(\mu)
	\end{equation}
	\item \textit{M}: set of all the possible values that $\mu$ can assume. Is initialized as the union of all breakpoints for each $\beta_{proj}$. At each step of \hyperref[algo:3]{Algorithm 3} M is reduced, removing all values of $\mu$ that for sure won't satisfy the linear constraint.
	\begin{equation}\label{eq:17}
	    M_0 = {\mu_i^l} \cup {\mu_i^u} \qquad i = 1:size(\beta_{proj})
	\end{equation}
	\item $\mu_L$ and $\mu_U$: this two values will represent the current estimate of the optimal upper/lower value of $\mu$ respectively. In \hyperref[algo:3]{Algorithm 3}, $\mu_L$ and $\mu_U$ will be initialized to +$\infty$ and -$\infty$ respectively. At each iteration one of the two value will be reassigned in order to decrease the range of possible values of $\mu$.
	An interesting observation derivable from the formulation of the algorithm is: \{$\mu_L^i$\} will be a sequence of \textit{nondecreasing underestimates} of $\mu_L^*$, and \{$\mu_U^i$\} will be a sequence of \textit{nonincreasing overestimates} of $\mu_U^*$.\\ Joining together the definition of the previous point \eqref{eq:17} and the current one we can define the optimal set of $\mu$ and the optimal upper/lower bounds (as stated in\parencite{Kiwiel2008}).
	\begin{equation}\label{eq:18}
    	\begin{aligned}
    	    M^* = [ \mu_L^*,\;\mu_U^*] \quad where \quad &\mu_L^* = \inf \{\mu: h(\mu) = 0\}\\&\mu_U^* = \sup \{\mu: h(\mu) = 0\}
    	\end{aligned}
	\end{equation}
	\end{itemize}
	\begin{algorithm}[H]\label{algo:3}
    	\DontPrintSemicolon
    	\small
    	\SetAlgoNoEnd
    	\caption{Convex Separable Knapsack Problem Algorithm}
    	\Begin{
    		\While{$M \neq \emptyset$}{
    		    choose $\hat{\mu}$ using \textbf{median of medians} approach over M\\
    		    compute $h(\hat{\mu})$\\
    		    \If{$h(\hat{\mu}) = 0$}{$\mu^* = \hat{\mu}$\\return $\mu^*$}
    		    \Else{\If{$h(\hat{\mu}) > 0$}{$\mu_L = \hat{\mu}\\M = \{\mu \in M : \hat{\mu}<\mu\}$}
    		    \Else{$\mu_U = \hat{\mu}\\M = \{\mu \in M : \hat{\mu}>\mu\}$}
    		    }
    		}
    		$\mu^* = \mu_L - h(\mu_L) \frac{\mu_U - \mu_L}{h(\mu_U) - h(\mu_L)}$\\
    		return $\mu^*$
    	}
    \end{algorithm}
    \vspace{0.5cm}
	The algorithm is quite simple. At each iteration a $\hat{\mu}$ is chosen from $M$ and the stopping condition is checked, returning $\hat{\mu}$ in the positive case. If we are not in stopping condition then $M$ is restricted appropriately. Eventually the algorithm terminates by either finding $\mu^*$ or by emptying $M$.\\
	In the second case (line 15) the emptiness of $M$ stands for having found the best possible approximation of $\mu^*_L$ and $\mu^*_U$ and no other breakpoints are left in the middle. Therefore the range [$\mu_L,\;\mu_U$] is a segment which formulation we can get and exploit (see \hyperref[appendixB]{Appendix B}).\\
	\newline
	The convergence of \hyperref[algo:3]{Algorithm 3} is strictly dependent on the choosing approach of $\hat{\mu}$. In the proposed pseudo-implementation the \textit{median of medians} algorithm is exploited, giving a double benefit. The algorithm allows for a linear time choice of $\hat{\mu}$ and an halving of $M$ per iteration. In conclusion this leads to an $\mathcal{O}(n)$ cost per iteration (\textit{median of medians}) and an $\mathcal{O}(log(n))$ number of iterations (halving of $M$), for an overall $\mathcal{O}(n\cdot log(n))$.
	
    \pagebreak
    \section{References}
    \printbibliography[heading=none]
    %APPENDIX A
    \pagebreak
    \section{Appendix A} \label{appendixA}
    Define the Lagrangian function
    \begin{equation}\label{eq:APP1}
        \begin{aligned}
            \Lagr = \frac{1}{2} \norm{w}^2 + C \sum_i (\xi_i + \xi_i^*) &+\sum_i \alpha_i (y_i - w\phi_i -b - \varepsilon - \xi_i) \\
            &+\sum_i \alpha_i (-y_i + w\phi_i -b - \varepsilon - \xi_i^*) \\
            &-\sum_i \mu_i\xi_i \\
            &-\sum_i \mu_i^*\xi_i^* \\
            where \quad \forall_i \: \xi_i\xi_i^* \geq 0
        \end{aligned}
    \end{equation}
    Variables of the two definition of the problem:
    \begin{equation*}
        \begin{aligned}
                &Primal \; problem \qquad && w, \; b, \; \xi_i, \; \xi_i^* \\
                &Dual \; Problem && \alpha_i, \; \alpha_i^*, \; \mu_i, \; \mu_i^*
        \end{aligned}
    \end{equation*}
    Next step is try to simplify the definition of the Lagrangian wrt the problem that needs to be solved. Since the objective is to find the \textit{minimum} the developments proceeds imposing this condition.
    \begin{subequations}
        \begin{align}
            &\frac {\partial \Lagr}{\partial w} = 0 \quad &&\longrightarrow \quad && w + \sum_i \alpha_i(-\phi_i) + \sum_i \alpha_i^*\phi_i = 0 \label{eq:APP2a}\\
            &\frac {\partial \Lagr}{\partial b} = 0 &&\longrightarrow && \sum_i -\alpha_i + \sum_i \alpha_i^* = 0 \label{eq:APP2b}\\
            &\frac {\partial \Lagr}{\partial \xi_i} = 0 &&\longrightarrow && C - \alpha_i - \mu_i = 0 \label{eq:APP2c}\\
            &\frac {\partial \Lagr}{\partial \xi_i^*} = 0 &&\longrightarrow && C - \alpha_i^* - \mu_i^* = 0 \label{eq:APP2d}
        \end{align}
    \end{subequations}
    From \eqref{eq:APP2a} the definition of w can be derived
    \begin{equation}\label{eq:APP3}
        w = \sum_i (\alpha_i - \alpha_i^*)\phi_i
    \end{equation}
    From \eqref{eq:APP2b} the first constraint on the Lagrangian variables is obtained
    \begin{equation}\label{eq:APP4}
        \sum_i (\alpha_i^* - \alpha_i) = 0
    \end{equation}
    While from \eqref{eq:APP2c}/\eqref{eq:APP2d} with some further development the second constraint on the Lagrangian variables can be defined
    \begin{equation*}
        \begin{aligned}
            &\alpha_i,\;\alpha_i^*,\;\mu_i,\;\mu_i^*\;\geq\;0 \quad \forall_i \\
            &C = \alpha_i + \mu_i\quad\longrightarrow\quad\alpha_i = C - \mu_i \\
            &\Longrightarrow\quad\alpha_i\;\in\;[0,\;C]\\
            &and\;equivalently\quad\alpha_i^*\;\in\;[0,\;C]
        \end{aligned}
    \end{equation*}
    Simplify \eqref{eq:APP1} using the substitution \eqref{eq:APP3}
    \begin{equation*}
        \begin{aligned}
            \Lagr\;=\;&\frac{1}{2} \sum_i \sum_j (\alpha_i - \alpha_i^*)(\alpha_j - \alpha_j^*)\phi_i\phi_j \\
            &-\sum_i \sum_j (\alpha_i - \alpha_i^*)(\alpha_j - \alpha_j^*)\phi_i\phi_j \\
            &+\sum_i (\alpha_i - \alpha_i^*)y_i
            +\sum_i (\alpha_i - \alpha_i^*)b
            -\sum_i (\alpha_i + \alpha_i^*)\varepsilon \\
            &+\sum_i \alpha_i(-\xi_i) + \sum_i\alpha_i^*(-\xi_i^*) \\
            &-\sum_i \mu_i\xi_i - \sum_i \mu_i^*\xi_i^* \\
            & +C\sum_i \xi_i + \xi_i^*
        \end{aligned}
    \end{equation*}
    Apply condition \eqref{eq:APP4} and \eqref{eq:APP2c} to simplify some terms and obtain the final formulation
    \begin{equation*}
        \begin{aligned}
            \Lagr(\alpha, \alpha^*)\;=\;&-\frac{1}{2}\sum_i\sum_j (\alpha_i - \alpha_i^*)(\alpha_j - \alpha_j^*)\phi_i\phi_j \\
            &+ \sum_i (\alpha_i - \alpha_i^*)y_i \\
            &- \sum_i (\alpha_i + \alpha_i^*)\varepsilon \\
            &With\;the\;constraints\qquad
            \begin{cases}
                \sum_i (\alpha_i^* - \alpha_i) = 0 \\
                \alpha_i\in[0,\;C] \\
                \alpha_i^*\in[0,\;C]
            \end{cases}
        \end{aligned}
    \end{equation*}
    % APPENDIX B
    \pagebreak
    \section{Appendix B}\label{appendixB}
    If $M = \emptyset$ then we have reached a point in the algorithm in which $\mu_L$ and $\mu_U$ are two consecutive breakpoint so $h(\mu)$ is linear in the interval [$\mu_L$, $\mu_U$].\\
    This can be exploited in order to compute the straight line that connects the two points.
    \begin{equation}\label{APPB:1}
        \frac{h(\mu) - h(\mu_L)}{h(\mu_U) - h(\mu_L)} = \frac{\mu - \mu_L}{\mu_U - \mu_L} 
    \end{equation}
    Given the formulation of \hyperref[algo:3]{Algorithm 3} the following statements are true at each step of the procedure.
    \begin{equation}\label{APPB:2}
        h(\mu_L) > 0 \qquad h(\mu_U) < 0
    \end{equation}
    Given the formulation for \eqref{APPB:1} and the assumptions in \eqref{APPB:2} for the \textit{intermediate zero theorem} there exists a point $\hat{\mu}$ where $h(\hat{\mu}) = 0$. In \eqref{eq:16}, $h(\mu)$ was defined as the function representing the linear constraint. In this case the linear constraint is $h(\mu) = 0$ so the point $\hat{\mu}$ is the optimal value of $\mu$.\\
    Substituting in \eqref{APPB:1} and isolating $\mu$, we can define $\mu^*$
    \begin{equation}
        \mu^* = \mu_L - [h(\mu_L) - 0]\frac{\mu_U - \mu_L}{h(\mu_U) - h(\mu_L)}
    \end{equation}

\end{document}